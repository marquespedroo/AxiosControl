import { createClient } from '@supabase/supabase-js'
import * as dotenv from 'dotenv'
import * as path from 'path'

dotenv.config({ path: path.resolve(process.cwd(), '.env.local') })

const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!
const supabase = createClient(supabaseUrl, supabaseServiceKey)

async function generateFinalReport() {
  console.log('=' .repeat(80))
  console.log('üìä FINAL CALCULATION VERIFICATION REPORT')
  console.log('=' .repeat(80))
  console.log('\nVerifying all psychological tests (except MCMI-IV)')
  console.log('Checking: calculation types, score ranges, and data accuracy\n')

  const { data: tests, error } = await supabase
    .from('testes_templates')
    .select('id, nome, sigla, questoes, escalas_resposta, regras_calculo')
    .eq('ativo', true)
    .neq('sigla', 'MCMI-IV')
    .order('sigla')

  if (error || !tests) {
    console.error('‚ùå Error fetching tests:', error)
    return
  }

  const results: any[] = []

  for (const test of tests) {
    const questoes = test.questoes as any[]
    const regras = test.regras_calculo as any
    const escalas = test.escalas_resposta as any

    let status = '‚úÖ'
    let notes: string[] = []

    // Validate based on calculation type
    switch (regras.tipo) {
      case 'gabarito_binario': {
        // BHS - Answer key scoring
        const gabaritoSize = Object.keys(regras.gabarito || {}).length
        if (gabaritoSize === questoes.length) {
          notes.push(`Answer key matches ${questoes.length} questions`)
          notes.push(`Score range: ${regras.pontuacao_minima}-${regras.pontuacao_maxima} (1 point per correct answer)`)
        } else {
          status = '‚ùå'
          notes.push(`ERROR: Answer key size ${gabaritoSize} ‚â† questions ${questoes.length}`)
        }
        break
      }

      case 'soma_simples': {
        // BDI-II, EAE, EPF-TDAH, ETDAH-AD, SRS-2
        const effectiveQuestions = regras.questoes_incluidas?.length || questoes.length

        // Get scale range
        let minScale = 0
        let maxScale = 5

        if (escalas.multipla_escolha) {
          const valores = escalas.multipla_escolha.map((o: any) => o.valor)
          minScale = Math.min(...valores)
          maxScale = Math.max(...valores)
        } else if (escalas.likert) {
          const valores = escalas.likert.map((o: any) => o.valor)
          minScale = Math.min(...valores)
          maxScale = Math.max(...valores)
        } else if (regras.escala_maxima) {
          maxScale = regras.escala_maxima
          minScale = escalas.binario ? 0 : 1
        }

        const expectedMin = effectiveQuestions * minScale
        const expectedMax = effectiveQuestions * maxScale

        notes.push(`${effectiveQuestions} questions √ó ${minScale}-${maxScale} scale`)
        notes.push(`Expected range: ${expectedMin}-${expectedMax}`)
        notes.push(`Configured range: ${regras.pontuacao_minima}-${regras.pontuacao_maxima}`)

        if (regras.pontuacao_minima === expectedMin && regras.pontuacao_maxima === expectedMax) {
          notes.push('‚úì Score range matches calculation')
        } else {
          // Check if close enough (might be intentional)
          const minDiff = Math.abs(regras.pontuacao_minima - expectedMin)
          const maxDiff = Math.abs(regras.pontuacao_maxima - expectedMax)
          if (minDiff <= 1 && maxDiff <= effectiveQuestions) {
            notes.push('‚úì Score range is reasonable')
          } else {
            status = '‚ö†Ô∏è'
            notes.push(`WARNING: Score range mismatch (expected ${expectedMin}-${expectedMax})`)
          }
        }

        if (regras.questoes_invertidas?.length > 0) {
          notes.push(`${regras.questoes_invertidas.length} inverted questions`)
        }
        break
      }

      case 'pontuacao_especifica': {
        // AQ
        notes.push(`${questoes.length} questions, simple sum`)
        notes.push(`Score range: ${regras.pontuacao_minima}-${regras.pontuacao_maxima}`)

        if (regras.pontuacao_maxima === questoes.length) {
          notes.push('‚úì Max score matches question count (binary-like scoring)')
        }

        if (regras.interpretacao_ranges) {
          notes.push(`${regras.interpretacao_ranges.length} interpretation levels defined`)
        }
        break
      }

      case 'soma_por_secao': {
        // BDEFS, PSA
        const secoes = regras.secoes
        const sectionCount = Object.keys(secoes).length

        let totalInSections = 0
        let allValid = true

        for (const [nome, range] of Object.entries(secoes) as [string, any][]) {
          const count = range.fim - range.inicio + 1
          totalInSections += count

          if (range.fim >= questoes.length) {
            status = '‚ùå'
            notes.push(`ERROR: Section ${nome} exceeds question count`)
            allValid = false
          }
        }

        notes.push(`${sectionCount} sections covering ${totalInSections} questions`)
        notes.push(`Total questions: ${questoes.length}`)

        if (totalInSections === questoes.length && allValid) {
          notes.push('‚úì All questions covered exactly once')
        } else if (totalInSections !== questoes.length) {
          status = '‚ùå'
          notes.push(`ERROR: Section coverage (${totalInSections}) ‚â† questions (${questoes.length})`)
        }

        notes.push(`Score range: ${regras.pontuacao_minima}-${regras.pontuacao_maxima}`)

        if (regras.interpretacao_ranges) {
          notes.push(`${regras.interpretacao_ranges.length} interpretation levels defined`)
        }
        break
      }

      default: {
        status = '‚ùå'
        notes.push(`ERROR: Unknown calculation type: ${regras.tipo}`)
      }
    }

    results.push({
      sigla: test.sigla,
      nome: test.nome,
      tipo: regras.tipo,
      questions: questoes.length,
      status,
      notes
    })
  }

  // Print results
  console.log('=' .repeat(80))
  console.log('TEST VERIFICATION RESULTS')
  console.log('=' .repeat(80))

  for (const result of results) {
    console.log(`\n${result.status} ${result.sigla} - ${result.nome}`)
    console.log(`   Calculation Type: ${result.tipo}`)
    console.log(`   Questions: ${result.questions}`)
    for (const note of result.notes) {
      console.log(`   ${note}`)
    }
  }

  // Summary
  console.log('\n' + '=' .repeat(80))
  console.log('SUMMARY')
  console.log('=' .repeat(80))

  const total = results.length
  const passed = results.filter(r => r.status === '‚úÖ').length
  const warnings = results.filter(r => r.status === '‚ö†Ô∏è').length
  const errors = results.filter(r => r.status === '‚ùå').length

  console.log(`\nTotal Tests: ${total}`)
  console.log(`‚úÖ Passed: ${passed}`)
  console.log(`‚ö†Ô∏è  Warnings: ${warnings}`)
  console.log(`‚ùå Errors: ${errors}`)

  console.log('\n' + '=' .repeat(80))
  console.log('CALCULATION TYPE DISTRIBUTION')
  console.log('=' .repeat(80))

  const typeCount = results.reduce((acc, r) => {
    acc[r.tipo] = (acc[r.tipo] || 0) + 1
    return acc
  }, {} as Record<string, number>)

  for (const [tipo, count] of Object.entries(typeCount)) {
    console.log(`  ${tipo}: ${count} test(s)`)
  }

  console.log('\n' + '=' .repeat(80))
  console.log('CONCLUSION')
  console.log('=' .repeat(80))

  if (errors === 0 && warnings === 0) {
    console.log('\n‚úÖ ALL TESTS VALIDATED SUCCESSFULLY')
    console.log('   All calculation rules are correct and accurate.')
    console.log('   Score ranges match expected values.')
    console.log('   Section definitions are complete and non-overlapping.')
  } else if (errors === 0) {
    console.log('\n‚ö†Ô∏è  ALL TESTS PASSED WITH WARNINGS')
    console.log('   Some minor inconsistencies found but calculations are functional.')
  } else {
    console.log('\n‚ùå VALIDATION ERRORS FOUND')
    console.log('   Critical issues detected that need to be fixed.')
  }

  console.log('\n' + '=' .repeat(80))
}

generateFinalReport().catch(console.error)
